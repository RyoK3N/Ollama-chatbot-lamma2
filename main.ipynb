{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import langchain\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_API_KEY=\"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\"\n",
    "LANGCHAIN_PROJECT=\"chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from ollama) (2.9.2)\n",
      "Requirement already satisfied: anyio in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ollama\n",
      "Requirement already satisfied: langchain-ollama in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-ollama) (0.3.27)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-ollama) (0.4.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.1.140)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ryok3n/miniconda3/envs/chatbot/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.1\n",
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat initialized. Type 'quit' to exit or 'reset' to clear history.\n",
      "\n",
      "Assistant: Hi there! *smiling* It's great to meet you! Is there something I can help you with or would you like to chat? Please feel free to ask me anything, and I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "from utils.config import load_config\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "class OllamaChat:\n",
    "    def __init__(self, config_path: str = \"config.toml\"):\n",
    "        # Load configuration\n",
    "        self.config = load_config(config_path)\n",
    "        \n",
    "        # Setup logging\n",
    "        self._setup_logging()\n",
    "        \n",
    "        # Setup base URL\n",
    "        self.base_url = f\"{self.config['model']['base_url']}/api/chat\"\n",
    "        \n",
    "        # Initialize conversation history\n",
    "        self.history = []\n",
    "        \n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure logging based on config settings\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=self.config['logging']['level'],\n",
    "            filename=self.config['logging']['file'],\n",
    "            format=self.config['logging']['format']\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def _make_request(self, messages: list) -> Dict[str, Any]:\n",
    "        \"\"\"Make a request to the Ollama API\"\"\"\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": self.config[\"model\"][\"name\"],\n",
    "                \"messages\": messages,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"temperature\": self.config[\"model\"][\"temperature\"],\n",
    "                    \"top_p\": self.config[\"model\"][\"top_p\"],\n",
    "                    \"num_predict\": self.config[\"model\"][\"max_tokens\"],\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                self.base_url,\n",
    "                json=payload,\n",
    "                timeout=self.config[\"api\"][\"request_timeout\"]\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            self.logger.error(f\"API request failed: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Send a message to the model and get a response\n",
    "        \n",
    "        Args:\n",
    "            user_input (str): The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            str: The model's response\n",
    "        \"\"\"\n",
    "        # Prepare messages including history\n",
    "        messages = [{\"role\": \"system\", \"content\": self.config[\"system\"][\"prompt\"]}]\n",
    "        messages.extend(self.history)\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        try:\n",
    "            # Get response from model\n",
    "            response = self._make_request(messages)\n",
    "            \n",
    "            # Extract assistant's message\n",
    "            assistant_message = response[\"message\"][\"content\"]\n",
    "            \n",
    "            # Update conversation history\n",
    "            self.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            \n",
    "            return assistant_message\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Chat failed: {str(e)}\")\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "            \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Clear the conversation history\"\"\"\n",
    "        self.history = []\n",
    "        self.logger.info(\"Conversation history reset\")\n",
    "\n",
    "def main():\n",
    "    # Initialize the chat client\n",
    "    chat_client = OllamaChat()\n",
    "    \n",
    "    print(\"Chat initialized. Type 'quit' to exit or 'reset' to clear history.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        elif user_input.lower() == 'reset':\n",
    "            chat_client.reset_conversation()\n",
    "            print(\"Conversation history cleared.\")\n",
    "            continue\n",
    "        \n",
    "        if user_input:\n",
    "            response = chat_client.chat(user_input)\n",
    "            print(f\"\\nAssistant: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
